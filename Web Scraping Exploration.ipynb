{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some scraping practices I did with Selenium and BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard imports and notation (Selenium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'C:\\Program Files (x86)\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "driver.get(\"your website link will go here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## driver.close() will close the tab, \n",
    "## driver.quit() close the window\n",
    "## driver.title will give the name of the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this page, the search bar had name 's'. send_keys will input this into the search bar. Keys.Return is like pressing the enter button in the search. Clear() will clear the textbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_name(\"s\")\n",
    "search.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.send_keys(\"test\")\n",
    "search.send_keys(Keys.RETURN)\n",
    "#element.clear() can remove the \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for different items on the webpage by inspecting then locating them by their html tag, ID, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This try except chunk is mainly asking the program to wait for 10s while the driver locatest the element -> can be By.ID, By.LINK_TEXT, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    main = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"main\"))\n",
    "    )\n",
    "    articles = main.find_elements_by_tag_name(\"time\")\n",
    "    for article in articles:\n",
    "        print(article.text)\n",
    "    \n",
    "except:\n",
    "    print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = driver.find_element_by_link_text(\"Python Programming\")\n",
    "link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    element = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.LINK_TEXT, \"Beginner Python Tutorials\"))\n",
    "    )\n",
    "    element.click()\n",
    "\n",
    "except:\n",
    "    print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    element = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"sow-button-19310003\"))\n",
    "    )\n",
    "    element.click()\n",
    "\n",
    "except:\n",
    "    print(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These are all the find_elements_by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_element_by_id\n",
    "find_element_by_name\n",
    "find_element_by_xpath\n",
    "#example of xpath '//div[@title=\"buyer-name\"]'\n",
    "find_element_by_link_text\n",
    "find_element_by_partial_link_text\n",
    "find_element_by_tag_name\n",
    "find_element_by_class_name\n",
    "find_element_by_css_selector\n",
    "find_elements_by_xpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## driver.back() and driver.forward() bring you back to the prev page/forward page\n",
    "## driver.close() closes popups/windows in focus. .quit() completely closes everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()\n",
    "driver.back()\n",
    "driver.quit() \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating a cookie clicker website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'C:\\Program Files (x86)\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "driver.get(\"https://orteil.dashnet.org/cookieclicker/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.implicitly_wait(5)\n",
    "\n",
    "cookie = driver.find_element_by_id(\"bigCookie\")\n",
    "cookie_count = driver.find_element_by_id(\"cookies\")\n",
    "items = [driver.find_element_by_id(\"productPrice\" + str(i)) for i in range(1,-1,-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ActionChains(driver)\n",
    "actions.click(cookie)\n",
    "\n",
    "for i in range(5000):\n",
    "    actions.perform()\n",
    "    count = int(cookie_count.text.split(\" \")[0])\n",
    "    for item in items:\n",
    "        value = int(item.text)\n",
    "        if value <= count:\n",
    "            upgrade_actions = ActionChains(driver)\n",
    "            upgrade_actions.move_to_element(item)\n",
    "            upgrade_actions.click()\n",
    "            upgrade_actions.perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the search box, typing inside and entering it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_id(\"search\")\n",
    "search.send_keys(\"monitor\")\n",
    "search.send_keys(Keys.RETURN)\n",
    "search.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is how to click buttons -> find the button name first then use ActionChains to perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ActionChains(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.click(limit)\n",
    "actions.perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = driver.find_elements_by_tag_name('option')\n",
    "print(len(options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard notation for opening the page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'C:\\Program Files (x86)\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "page = 'random website link goes here'\n",
    "driver.get(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is how I found the search bar and tried to search for laptops on the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_id('q')\n",
    "search.send_keys('laptop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is how I found details such as Prices, Product Name etc that I want to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = driver.find_elements_by_xpath('//span[@class=\"c13VH6\"]')\n",
    "for price in prices:\n",
    "    print(price.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = driver.find_elements_by_xpath('//div[@class=\"c16H9d\"]')\n",
    "for name in names:\n",
    "    print(name.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining it all together and writing it into a .csv file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'C:\\Program Files (x86)\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "for i in range(10):\n",
    "    page = 'https://www.lazada.sg/lenovo/?from=input&page=' + str(i + 1) + '&q=laptop'\n",
    "    driver.get(page)\n",
    "    \n",
    "    if i == 0:\n",
    "        filename = \"Fourth Webscrape.csv\"\n",
    "        f = open(filename, 'w')\n",
    "\n",
    "        headers = 'Product Name, Price\\n'\n",
    "        f.write(headers)\n",
    "    \n",
    "    else:\n",
    "        filename = \"Fourth Webscrape.csv\"\n",
    "        f = open(filename, 'a')\n",
    "        f.write\n",
    "    \n",
    "    prices = driver.find_elements_by_xpath('//span[@class=\"c13VH6\"]')\n",
    "    names = driver.find_elements_by_xpath('//div[@class=\"c16H9d\"]')\n",
    "    \n",
    "    name = names[i]\n",
    "    price = prices[i]\n",
    "        \n",
    "    f.write(name.replace(',','|') + ',' + price.replace(',', ' ') + '\\n')\n",
    "    f.close()\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing this on a particular e-commerce store to get price of sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'C:\\Program Files (x86)\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "driver.get(\"link goes here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is how I found the brand names and the second cell shows how to print each of the brand name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = driver.find_elements_by_xpath('//span[@class=\"b-catalogList__itmBrand fsm txtDark uc\"]')\n",
    "print(len(brands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for brand in brands:\n",
    "    print(brand.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is how I found the model names and the second cells shows how to print each model name. Use len() to check if data extracted tallies with the website being searched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = driver.find_elements_by_xpath('//em[@class=\"b-catalogList__itmTitle fss\"]')\n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    print(model.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is how to find the prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = driver.find_elements_by_xpath('//span[@class=\"b-catalogList__itmPriceBox itm-priceBox fsm txtDark\"]')\n",
    "print(len(prices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is how to write each csv file -> convert them to excel files afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Eighth Webscrabe.csv'\n",
    "\n",
    "f = open(filename, 'w')\n",
    "\n",
    "headers = 'Brand,Name,Price($)\\n'\n",
    "\n",
    "f.write(headers)\n",
    "\n",
    "for i in range(99):\n",
    "    brand = brands[i].text.replace(',', \" \")\n",
    "    model = models[i].text.replace(',', \" \")\n",
    "    price = prices[i].text.replace(',', \" \")\n",
    "    price = price.replace('\\n', ' | ')\n",
    "   \n",
    "    f.write(brand + ',' + model + ',' + price + \"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is how I find the page numbers at the bottom to click to move on to the next page. Check what each number in next_page represents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page = driver.find_elements_by_xpath('//a[@class=\"page-item\"]')\n",
    "print(next_page[3].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ActionChains(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.click(next_page[3])\n",
    "actions.perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard imports and notations (BeautifulSoup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beautiful soup will parse the HTML text, URL lib will grab the page\n",
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "for i in range(4):\n",
    "    my_url = 'https://www.courts.com.sg/computing-mobile/monitors-projectors/monitors?p=' + str(i+1) + '&product_list_limit=32'\n",
    "\n",
    "    #This will open up the page\n",
    "    uClient = uReq(my_url)\n",
    "\n",
    "    #This reads the info within the page, remember to close the page after\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "\n",
    "    #\"html.parser\" tells it to parse as a html file\n",
    "    page_soup = soup(page_html, \"html.parser\")\n",
    "\n",
    "    #print(page_soup.h1)\n",
    "    #print(page_soup.p)\n",
    "    #print(page_soup.body.span)\n",
    "\n",
    "    #Grabs each individual product\n",
    "    containers = page_soup.findAll(\"div\",{\"class\": \"item-container\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on Courts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    my_url = 'https://www.stadiumgoods.com/air-jordan-1-retro-high-og-light-smoke-grey-555088-126'\n",
    "\n",
    "    uClient = uReq(my_url)\n",
    "\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "\n",
    "    page_soup = soup(page_html, 'html.parser')\n",
    "\n",
    "    containers = page_soup.find_all(\"li\", class_ = \"item product product-item\")\n",
    "    #print(len(containers))\n",
    "\n",
    "    if i == 0:\n",
    "        filename = \"First Webscrape.csv\"\n",
    "        f = open(filename, 'w')\n",
    "        headers = 'Product Name, Price ($), Screen Dimensions \\n'\n",
    "        \n",
    "        f.write(headers)\n",
    "    else:\n",
    "        filename = \"First Webscrape.csv\"\n",
    "        f = open(filename, 'a')\n",
    "        f.write\n",
    "        \n",
    "    for container in containers:\n",
    "        name = container.div.a.img['alt']\n",
    "        #print(name)\n",
    "\n",
    "        price = (container.find_all(\"span\", class_ = \"price-wrapper\"))[0].text\n",
    "        #print(price)\n",
    "\n",
    "        size = (container.find_all(\"ul\", class_ = \"navision-spec\")[0])\n",
    "        screen = (size.li.text.replace(\"Screen Size:\", \" \")).strip()\n",
    "        #print(screen.strip())\n",
    "        \n",
    "        f.write(name + \",\" + price.replace(\",\",\" \") + \",\" + screen + \"\\n\") \n",
    "        \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on bestdenki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_url = 'https://www.bestdenki.com.sg/catalog/computer/category/monitor-67'\n",
    "\n",
    "uClient = uReq(my_url)\n",
    "\n",
    "page_html = uClient.read()\n",
    "uClient.close()\n",
    "\n",
    "page_soup = soup(page_html, 'html.parser')\n",
    "\n",
    "containers = page_soup.find_all(\"div\", class_ = \"col-md-3 col-sm-6 col-xs-6 hover-border\")\n",
    "#print(len(containers))\n",
    "\n",
    "filename = \"Second Webscrape.csv\"\n",
    "f = open(filename, 'w')\n",
    "\n",
    "headers = 'Product Name, Current Price ($), Original Price($), Screen Dimensions\\n'\n",
    "\n",
    "f.write(headers)\n",
    "\n",
    "for container in containers:\n",
    "    name = ''\n",
    "    brand = container.h3.text.strip()\n",
    "    des = (container.find_all(\"div\", class_ = \"title\"))[0].h3.text.strip()\n",
    "    \n",
    "    name = brand + \" \" + des\n",
    "\n",
    "    price = container.find_all(\"div\", class_ = \"price\")[0].text.strip()\n",
    "    \n",
    "    price = price.split()\n",
    "    curr_price = price[0]\n",
    "    \n",
    "    try:\n",
    "        old_price = price[1]\n",
    "        \n",
    "    except IndexError:\n",
    "        old_price = \"No Discount\"\n",
    "    \n",
    "    size = ''\n",
    "    for i in des:\n",
    "        if i.isdigit():\n",
    "            #print(i)\n",
    "            while len(size) < 2:\n",
    "                size = size + i\n",
    "                break\n",
    "    \n",
    "    f.write(name + ',' + curr_price + ',' + old_price + ',' + size + \"\\n\")\n",
    "    \n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
